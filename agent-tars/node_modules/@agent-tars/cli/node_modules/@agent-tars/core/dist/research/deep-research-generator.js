/**
* Copyright (c) 2025 Bytedance, Inc. and its affiliates.
* SPDX-License-Identifier: Apache-2.0
*/
"use strict";
var __webpack_require__ = {};
(()=>{
    __webpack_require__.n = (module)=>{
        var getter = module && module.__esModule ? ()=>module['default'] : ()=>module;
        __webpack_require__.d(getter, {
            a: getter
        });
        return getter;
    };
})();
(()=>{
    __webpack_require__.d = (exports1, definition)=>{
        for(var key in definition)if (__webpack_require__.o(definition, key) && !__webpack_require__.o(exports1, key)) Object.defineProperty(exports1, key, {
            enumerable: true,
            get: definition[key]
        });
    };
})();
(()=>{
    __webpack_require__.o = (obj, prop)=>Object.prototype.hasOwnProperty.call(obj, prop);
})();
(()=>{
    __webpack_require__.r = (exports1)=>{
        if ('undefined' != typeof Symbol && Symbol.toStringTag) Object.defineProperty(exports1, Symbol.toStringTag, {
            value: 'Module'
        });
        Object.defineProperty(exports1, '__esModule', {
            value: true
        });
    };
})();
var __webpack_exports__ = {};
__webpack_require__.r(__webpack_exports__);
__webpack_require__.d(__webpack_exports__, {
    DeepResearchGenerator: ()=>DeepResearchGenerator
});
const mcp_agent_namespaceObject = require("@multimodal/mcp-agent");
const external_uuid_namespaceObject = require("uuid");
const external_fs_namespaceObject = require("fs");
var external_fs_default = /*#__PURE__*/ __webpack_require__.n(external_fs_namespaceObject);
function _define_property(obj, key, value) {
    if (key in obj) Object.defineProperty(obj, key, {
        value: value,
        enumerable: true,
        configurable: true,
        writable: true
    });
    else obj[key] = value;
    return obj;
}
class DeepResearchGenerator {
    async generateReport(llmClient, resolvedModel, eventStream, options, abortSignal) {
        try {
            this.logger.info(`Generating research report: ${options.title}`);
            if (null == abortSignal ? void 0 : abortSignal.aborted) {
                this.logger.info('Report generation aborted before starting');
                throw new Error('Report generation aborted');
            }
            const messageId = `research-report-${(0, external_uuid_namespaceObject.v4)()}`;
            const relevantData = this.extractRelevantData(eventStream);
            if (!this.hasEnoughInformationForReport(relevantData)) {
                this.logger.warn('Insufficient information to generate a detailed report');
                const simpleAnswerEvent = eventStream.createEvent(mcp_agent_namespaceObject.EventType.FINAL_ANSWER, {
                    content: "I don't have enough information to generate a detailed report on this topic. Please provide more context or try a different query.",
                    isDeepResearch: false,
                    title: options.title,
                    messageId
                });
                eventStream.sendEvent(simpleAnswerEvent);
                return {
                    success: false,
                    message: 'Insufficient information for report generation'
                };
            }
            const reportStructure = await this.generateReportStructure(llmClient, resolvedModel, relevantData, options, abortSignal);
            console.log('reportStructure', reportStructure);
            await this.generateAndStreamReport(llmClient, resolvedModel, relevantData, reportStructure, messageId, options, abortSignal);
            const finalEvent = eventStream.createEvent(mcp_agent_namespaceObject.EventType.FINAL_ANSWER, {
                content: reportStructure.fullContent || 'Research report generated successfully.',
                isDeepResearch: true,
                title: options.title,
                format: options.format,
                messageId
            });
            eventStream.sendEvent(finalEvent);
            return {
                success: true,
                message: 'Research report generated successfully'
            };
        } catch (error) {
            this.logger.error(`Failed to generate research report: ${error}`);
            throw error;
        }
    }
    hasEnoughInformationForReport(relevantData) {
        const hasSubstantialContent = relevantData.browserContent && relevantData.browserContent.length > 0 || relevantData.searchResults && relevantData.searchResults.length > 0 || relevantData.environmentImages && relevantData.environmentImages.length > 0 || relevantData.environmentTexts && relevantData.environmentTexts.some((text)=>text && text.length > 200);
        this.logger.debug(`Information check: ${hasSubstantialContent ? 'Sufficient' : 'Insufficient'} data for report`);
        return hasSubstantialContent;
    }
    extractRelevantData(eventStream) {
        const events = eventStream.getEvents();
        const userMessages = events.filter((e)=>e.type === mcp_agent_namespaceObject.EventType.USER_MESSAGE);
        const toolResults = events.filter((e)=>e.type === mcp_agent_namespaceObject.EventType.TOOL_RESULT);
        const assistantMessages = events.filter((e)=>e.type === mcp_agent_namespaceObject.EventType.ASSISTANT_MESSAGE);
        const environmentInputs = events.filter((e)=>e.type === mcp_agent_namespaceObject.EventType.ENVIRONMENT_INPUT);
        const originalQuery = userMessages.length > 0 ? userMessages[0].content : '';
        const toolResultsByName = {};
        toolResults.forEach((result)=>{
            const toolName = result.name || 'unknown';
            if (!toolResultsByName[toolName]) toolResultsByName[toolName] = [];
            toolResultsByName[toolName].push(result);
        });
        const browserContent = toolResults.filter((result)=>{
            var _result_name, _result_name1, _result_name2;
            return (null === (_result_name = result.name) || void 0 === _result_name ? void 0 : _result_name.includes('browser_get_markdown')) || (null === (_result_name1 = result.name) || void 0 === _result_name1 ? void 0 : _result_name1.includes('browser_get_text')) || (null === (_result_name2 = result.name) || void 0 === _result_name2 ? void 0 : _result_name2.includes('browser_get_html'));
        }).map((result)=>result.content).filter(Boolean);
        const searchResults = toolResults.filter((result)=>{
            var _result_name;
            return null === (_result_name = result.name) || void 0 === _result_name ? void 0 : _result_name.includes('search');
        }).map((result)=>result.content).filter(Boolean);
        const environmentImages = [];
        const environmentTexts = [];
        environmentInputs.forEach((input)=>{
            if (Array.isArray(input.content)) input.content.forEach((contentPart)=>{
                var _contentPart_image_url;
                if ('image_url' === contentPart.type && (null === (_contentPart_image_url = contentPart.image_url) || void 0 === _contentPart_image_url ? void 0 : _contentPart_image_url.url)) environmentImages.push(contentPart);
                else if ('text' === contentPart.type && contentPart.text) environmentTexts.push(contentPart.text);
            });
            else if ('string' == typeof input.content) environmentTexts.push(input.content);
        });
        this.logger.info(`Extracted ${environmentImages.length} images and ${environmentTexts.length} text blocks from environment inputs`);
        return {
            userMessages,
            toolResults,
            assistantMessages,
            environmentInputs,
            environmentImages,
            environmentTexts,
            originalQuery,
            toolResultsByName,
            browserContent,
            searchResults,
            allEvents: events
        };
    }
    async generateReportStructure(llmClient, resolvedModel, relevantData, options, abortSignal) {
        try {
            var _response_choices__message, _response_choices_, _reportStructure_sections;
            this.logger.info('Generating report structure');
            if (null == abortSignal ? void 0 : abortSignal.aborted) {
                this.logger.info('Report structure generation aborted');
                throw new Error('Report structure generation aborted');
            }
            const structurePromptContent = this.createStructurePromptContent(relevantData, options);
            const response = await llmClient.chat.completions.create({
                model: resolvedModel.model,
                response_format: {
                    type: 'json_object'
                },
                messages: [
                    {
                        role: 'system',
                        content: "You are an expert research report organizer. Based on the information provided, create a logical structure for a comprehensive research report. Follow EXACTLY what the user is asking for - do not invent topics that aren't covered in the data provided."
                    },
                    {
                        role: 'user',
                        content: structurePromptContent
                    }
                ]
            }, {
                signal: abortSignal
            });
            const structureContent = (null === (_response_choices_ = response.choices[0]) || void 0 === _response_choices_ ? void 0 : null === (_response_choices__message = _response_choices_.message) || void 0 === _response_choices__message ? void 0 : _response_choices__message.content) || '{}';
            const reportStructure = JSON.parse(structureContent);
            this.logger.info(`Generated report structure with ${(null === (_reportStructure_sections = reportStructure.sections) || void 0 === _reportStructure_sections ? void 0 : _reportStructure_sections.length) || 0} sections`);
            return reportStructure;
        } catch (error) {
            this.logger.error(`Error generating report structure: ${error}`);
            return {
                title: options.title,
                sections: [
                    'Introduction',
                    'Key Findings',
                    'Conclusion'
                ],
                fullContent: ''
            };
        }
    }
    createStructurePromptContent(relevantData, options) {
        const promptContent = [];
        promptContent.push({
            type: 'text',
            text: this.createStructurePromptText(relevantData, options)
        });
        if (relevantData.environmentImages && relevantData.environmentImages.length > 0) {
            const imagesToInclude = relevantData.environmentImages.slice(0, 3);
            this.logger.debug(`Including ${imagesToInclude.length} images in structure prompt`);
            for (const image of imagesToInclude)promptContent.push({
                type: 'image_url',
                image_url: {
                    url: image.image_url.url
                }
            });
        }
        return promptContent;
    }
    createStructurePromptText(relevantData, options) {
        const userQuery = relevantData.originalQuery || 'Research request';
        const toolCounts = {};
        relevantData.toolResults.forEach((result)=>{
            const toolName = result.name || 'unknown';
            toolCounts[toolName] = (toolCounts[toolName] || 0) + 1;
        });
        const toolSummary = Object.entries(toolCounts).map(([tool, count])=>`${tool}: ${count} times`).join('\n');
        let dataPreview = '';
        if (relevantData.browserContent && relevantData.browserContent.length > 0) {
            const samples = relevantData.browserContent.slice(0, 3).map((content)=>{
                if ('string' == typeof content) return content.substring(0, 300) + (content.length > 300 ? '...' : '');
                return JSON.stringify(content).substring(0, 300) + '...';
            });
            dataPreview += `\nWebpage content samples:\n${samples.join('\n\n')}\n`;
        }
        if (relevantData.searchResults && relevantData.searchResults.length > 0) {
            dataPreview += `\nSearch result samples:\n`;
            let searchSample = '';
            try {
                const firstSearchResult = relevantData.searchResults[0];
                searchSample = Array.isArray(firstSearchResult) ? firstSearchResult.slice(0, 3).map((item)=>`- ${item.title || 'Untitled'}: ${(item.snippet || '').substring(0, 100)}...`).join('\n') : 'object' == typeof firstSearchResult ? JSON.stringify(firstSearchResult).substring(0, 300) + '...' : String(firstSearchResult).substring(0, 300) + '...';
            } catch (e) {
                searchSample = 'Error parsing search results';
            }
            dataPreview += searchSample + '\n';
        }
        if (relevantData.environmentTexts && relevantData.environmentTexts.length > 0) {
            dataPreview += `\nEnvironment content samples:\n`;
            const textSamples = relevantData.environmentTexts.slice(0, 3).map((text)=>text.substring(0, 300) + (text.length > 300 ? '...' : '')).join('\n\n');
            dataPreview += textSamples + '\n';
        }
        if (relevantData.environmentImages && relevantData.environmentImages.length > 0) dataPreview += `\nAdditional context: ${relevantData.environmentImages.length} screenshot images have been included for visual reference.\n`;
        return `
    I need to create a factual research report with the title: "${options.title}" that STRICTLY answers the original request.
    
    The original research request was:
    "${userQuery}"
    
    During my research, I used these tools:
    ${toolSummary}
    
    Here are samples of the data I've collected:
    ${dataPreview}
    
    Please create a structured outline for a ${options.format || 'detailed'} research report that:
    1. DIRECTLY addresses the original request
    2. ONLY includes sections that can be supported by the collected data
    3. Does NOT include sections for which we lack sufficient information
    4. Follows a logical flow from introduction to conclusion
    5. Considers both textual content AND any screenshots/images provided
    
    Return a JSON object with:
    1. "title": The report title (based on the original request)
    2. "sections": An array of section names that would create a comprehensive research report
    
    IMPORTANT: The sections should ONLY cover topics for which we have actual data. DO NOT include sections that would require inventing information.
    `;
    }
    async generateAndStreamReport(llmClient, resolvedModel, relevantData, reportStructure, messageId, options, abortSignal) {
        this.logger.info('Generating and streaming report');
        if (null == abortSignal ? void 0 : abortSignal.aborted) {
            this.logger.info('Report streaming aborted before starting');
            throw new Error('Report streaming aborted');
        }
        let fullReport = `# ${reportStructure.title || options.title}\n\n`;
        if (relevantData.originalQuery) {
            const querySection = `> Original question: ${relevantData.originalQuery}\n\n`;
            fullReport += querySection;
            this.streamReportChunk(querySection, messageId, false);
        }
        const toc = this.generateTableOfContents(reportStructure.sections);
        fullReport += toc;
        this.streamReportChunk(toc, messageId, false);
        for (const section of reportStructure.sections){
            const sectionTitle = `\n\n## ${section}\n\n`;
            fullReport += sectionTitle;
            this.streamReportChunk(sectionTitle, messageId, false);
            const sectionContent = await this.streamSectionContent(llmClient, resolvedModel, section, relevantData, options, messageId, fullReport, abortSignal);
            fullReport += sectionContent;
            const separator = '\n\n';
            fullReport += separator;
            this.streamReportChunk(separator, messageId, false);
        }
        reportStructure.fullContent = fullReport;
    }
    async streamSectionContent(llmClient, resolvedModel, sectionTitle, relevantData, options, messageId, fullReport, abortSignal) {
        try {
            this.logger.info(`Streaming section content: ${sectionTitle}`);
            const sectionPromptContent = this.createSectionPromptContent(sectionTitle, relevantData, options);
            external_fs_default().writeFileSync(`${sectionPromptContent}-${Date.now()}.json`, JSON.stringify(sectionPromptContent, null, 2), 'utf-8');
            const stream = await llmClient.chat.completions.create({
                model: resolvedModel.model,
                stream: true,
                messages: [
                    {
                        role: 'system',
                        content: `You are an expert research analyst. Generate detailed content for the "${sectionTitle}" section of a research report. IMPORTANT: Only include information that is directly supported by the provided data - do NOT invent facts, statistics, or examples. If there is insufficient data for a comprehensive section, acknowledge the limitations and focus on what is available.`
                    },
                    {
                        role: 'user',
                        content: sectionPromptContent
                    }
                ]
            }, {
                signal: abortSignal
            });
            let sectionContent = '';
            for await (const chunk of stream){
                var _chunk_choices__delta, _chunk_choices_;
                const content = (null === (_chunk_choices_ = chunk.choices[0]) || void 0 === _chunk_choices_ ? void 0 : null === (_chunk_choices__delta = _chunk_choices_.delta) || void 0 === _chunk_choices__delta ? void 0 : _chunk_choices__delta.content) || '';
                if (content) {
                    sectionContent += content;
                    this.streamReportChunk(content, messageId, false);
                }
            }
            return sectionContent;
        } catch (error) {
            this.logger.error(`Error streaming section ${sectionTitle}: ${error}`);
            const errorMessage = `\n\n*Error generating content for ${sectionTitle}: ${error}*\n\n`;
            this.streamReportChunk(errorMessage, messageId, false);
        }
    }
    createSectionPromptContent(sectionTitle, relevantData, options) {
        const promptContent = [];
        promptContent.push({
            type: 'text',
            text: this.createSectionPromptText(sectionTitle, relevantData, options)
        });
        if (relevantData.environmentImages && relevantData.environmentImages.length > 0) {
            const imagesToInclude = relevantData.environmentImages.slice(0, 2);
            for (const image of imagesToInclude)promptContent.push({
                type: 'image_url',
                image_url: {
                    url: image.image_url.url
                }
            });
            this.logger.debug(`Including ${imagesToInclude.length} images in "${sectionTitle}" section prompt`);
        }
        return promptContent;
    }
    streamReportChunk(content, messageId, isComplete) {
        const streamingEvent = this.eventStream.createEvent(mcp_agent_namespaceObject.EventType.FINAL_ANSWER_STREAMING, {
            content,
            isDeepResearch: true,
            isComplete,
            messageId
        });
        this.eventStream.sendEvent(streamingEvent);
    }
    generateTableOfContents(sections) {
        let toc = '## Table of Contents\n\n';
        sections.forEach((section, index)=>{
            toc += `${index + 1}. [${section}](#${section.toLowerCase().replace(/\s+/g, '-')})\n`;
        });
        toc += '\n\n';
        return toc;
    }
    createSectionPromptText(sectionTitle, relevantData, options) {
        const originalQuery = relevantData.originalQuery || 'Research request';
        const relevantTools = relevantData.toolResults;
        const toolContext = relevantTools.map((tool)=>{
            let content = '';
            try {
                content = 'string' == typeof tool.content ? tool.content : JSON.stringify(tool.content);
            } catch (e) {
                content = 'Error formatting content';
            }
            return `Tool: ${tool.name || 'unknown'}\nContent: ${content.substring(0, 800)}${content.length > 800 ? '...' : ''}`;
        }).join('\n\n');
        let environmentContext = '';
        if (relevantData.environmentTexts && relevantData.environmentTexts.length > 0) {
            const textSamples = relevantData.environmentTexts.slice(0, 2).map((text)=>text.substring(0, 800) + (text.length > 800 ? '...' : '')).join('\n\n');
            environmentContext = `\nEnvironment Content:\n${textSamples}\n`;
        }
        const imageReference = relevantData.environmentImages && relevantData.environmentImages.length > 0 ? "\n\nNOTE: Screenshots have been provided. Analyze any visual information that's relevant to this section." : '';
        return `
    I'm writing a research report titled "${options.title}" based on the original request: "${originalQuery}"
    
    I need to generate content for the "${sectionTitle}" section of the report.
    
    Here is the relevant information from my research that specifically relates to this section:
    ${toolContext || 'Limited data available for this section.'}
    ${environmentContext}
    ${imageReference}
    
    STRICT GUIDELINES:
    1. ONLY use information from the provided data - DO NOT invent facts, statistics, examples, or quotes
    2. If the data is insufficient, acknowledge the limitations and focus only on what is available
    3. Make sure all content directly addresses the original request
    4. Use proper Markdown formatting with headings, paragraphs, and lists as appropriate
    5. Write in a professional, analytical tone
    6. If there is insufficient data for this section, keep it brief and acknowledge the limitations
    7. Reference visual information from screenshots when relevant to this section
    
    Write the content for the "${sectionTitle}" section now, ensuring EVERYTHING is supported by the provided data.
    `;
    }
    constructor(logger, eventStream){
        _define_property(this, "logger", void 0);
        _define_property(this, "eventStream", void 0);
        this.logger = logger;
        this.eventStream = eventStream;
        this.logger = logger.spawn('DeepResearchGenerator');
    }
}
var __webpack_export_target__ = exports;
for(var __webpack_i__ in __webpack_exports__)__webpack_export_target__[__webpack_i__] = __webpack_exports__[__webpack_i__];
if (__webpack_exports__.__esModule) Object.defineProperty(__webpack_export_target__, '__esModule', {
    value: true
});

//# sourceMappingURL=deep-research-generator.js.map